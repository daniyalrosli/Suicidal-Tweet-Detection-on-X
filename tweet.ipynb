{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load dataset\n",
    "df = pd.read_csv('/Users/daniyalrosli/Suicidal-Tweet-Detection-on-X/Suicide_Ideation_Dataset(Twitter-based).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                   Tweet  \\\n",
       "0                                     making some lunch   \n",
       "1                           @Alexia You want his money.   \n",
       "2     @dizzyhrvy that crap took me forever to put to...   \n",
       "3     @jnaylor #kiwitweets Hey Jer! Since when did y...   \n",
       "4     Trying out &quot;Delicious Library 2&quot; wit...   \n",
       "...                                                 ...   \n",
       "1782    i have forgotten how much i love my Nokia N95-1   \n",
       "1783  Starting my day out with a positive attitude! ...   \n",
       "1784  @belledame222 Hey, it's 5 am...give a girl som...   \n",
       "1785  2 drunken besties stumble into my room and we ...   \n",
       "1786  @dancingbonita &quot;I friggin love you!!!&quo...   \n",
       "\n",
       "                      Suicide  \n",
       "0            Not Suicide post  \n",
       "1            Not Suicide post  \n",
       "2     Potential Suicide post   \n",
       "3            Not Suicide post  \n",
       "4            Not Suicide post  \n",
       "...                       ...  \n",
       "1782         Not Suicide post  \n",
       "1783         Not Suicide post  \n",
       "1784         Not Suicide post  \n",
       "1785         Not Suicide post  \n",
       "1786         Not Suicide post  \n",
       "\n",
       "[1787 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1785</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1777</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Became as hot as the persistent days resting h...</td>\n",
       "      <td>Not Suicide post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet           Suicide\n",
       "count                                                1785              1787\n",
       "unique                                               1777                 2\n",
       "top     Became as hot as the persistent days resting h...  Not Suicide post\n",
       "freq                                                    2              1127"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1787 entries, 0 to 1786\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Tweet    1785 non-null   object\n",
      " 1   Suicide  1787 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset info :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1787 entries, 0 to 1786\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Tweet    1785 non-null   object\n",
      " 1   Suicide  1787 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 28.1+ KB\n",
      "None\n",
      "First 5 rows:\n",
      "                                               Tweet                  Suicide\n",
      "0                                  making some lunch         Not Suicide post\n",
      "1                        @Alexia You want his money.         Not Suicide post\n",
      "2  @dizzyhrvy that crap took me forever to put to...  Potential Suicide post \n",
      "3  @jnaylor #kiwitweets Hey Jer! Since when did y...         Not Suicide post\n",
      "4  Trying out &quot;Delicious Library 2&quot; wit...         Not Suicide post\n"
     ]
    }
   ],
   "source": [
    "#exploratory data analysis(eda)\n",
    "\n",
    "print(\"dataset info :\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values :\n",
      "Tweet      2\n",
      "Suicide    0\n",
      "dtype: int64\n",
      "Tweet      1785\n",
      "Suicide    1787\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing values\n",
    "\n",
    "print(\"Missing Values :\")\n",
    "print(df.isnull().sum())\n",
    "print(df.notnull().sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the missing values\n",
    "\n",
    "df = df.dropna(subset= ['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value : \n",
      "Tweet      0\n",
      "Suicide    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing value : \")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      6\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSuicide\u001b[39m\u001b[38;5;124m'\u001b[39m], palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data['Suicide'], palette='viridis')\n",
    "plt.title('Distribution of Non-Suicidal Tweet vs Potentially Suicidal Tweets')\n",
    "plt.xticks(ticks=[0,1], labels=[\"Non-Suicidal\", \"Potentially Suicidal \"])\n",
    "plt.show()\n",
    "\n",
    "print(\"Label Counts:\")\n",
    "print(data['Suicide'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       357\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#lr model\n",
    "\n",
    "# Linear Regression model\n",
    "\n",
    "# Assuming 'Tweet' column has been preprocessed and vectorized into 'X' and 'Suicide' column is the target 'y'\n",
    "# Here, we use TfidfVectorizer for text vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Tweet'])\n",
    "y = df['Suicide'].apply(lambda x: 1 if x == 'Potential Suicide post' else 0)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Since Linear Regression outputs continuous values, we need to threshold them to get binary classification\n",
    "y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_class))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       357\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       357\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=40, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END max_depth=50, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "Best Decision Tree Accuracy: 1.0\n",
      "Best Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       357\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# handle overfitting\n",
    "\n",
    "# BEGIN: Handle overfitting using GridSearchCV for Decision Tree\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with DecisionTreeClassifier\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions with the best model\n",
    "y_pred_best_dt = best_dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_best_dt))\n",
    "print(\"Best Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_best_dt))\n",
    "# END: Handle overfitting using GridSearchCV for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean cross-validation score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(dt_model, X, y, cv=5)\n",
    "\n",
    "# Print the cross-validation scores and their mean\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "cmake"
    }
   },
   "outputs": [],
   "source": [
    "# Check for data leakage by ensuring no overlap between training and test sets\n",
    "train_indices = set(X_train.indices)\n",
    "test_indices = set(X_test.indices)\n",
    "\n",
    "# Check if there is any intersection between the training and test indices\n",
    "leakage = train_indices.intersection(test_indices)\n",
    "\n",
    "if leakage:\n",
    "    print(\"Data leakage detected!\")\n",
    "else:\n",
    "    print(\"No data leakage detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
